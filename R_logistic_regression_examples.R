## Stat 431 Assignment 2 ##
getwd()

# Question 1

# (a)
# ?????????????????????take log???take??????Exponential???????????????Exp?????????
# ??????????????????y,??????y??????????????????theta??????unknown???,??????????????????miu???sigma??????????????????

# ??????,??????


# (b) (c) ?
# ?????????????????????codes,???????????????????????????
# ?????? method1
pdf_logistic <- function(y,mu,sigma){
  #?????????????????????:pdf???????????? pi*exp(xx)...
}

pdf_logiscti(10,0,1)

cdf_logistic <- function(y,mu,sigma){
  #cdf????????????
}

cdf_logistic(10,0,1)

# ?????? method2
# ??????R?????????logistic distribution???pdf???Cdf???????????????
# pdf: dlogis(x,mean,sigma)
# cdf: plogis(q, mean, sigma) ; ??????f(x)?????????,pdf???cdf??????????????????
# ????????????????????????

dlogis(10,0,1*sqrt(3)/pi)
plogis(10,0,1*sqrt(3)/pi)


# ??????
# x <- seq(????????????,????????????,????????????)
# ?????? seq(-5,-5,0.1) ?????????x?????????????????????pdf / cdf
# ??????apply or sapply ???????????????x????????????????????????????????????
# ??????y????????? y <- .....
# ?????? plot(x, y, xlab=..., ylab="..", main="...")

# ???logistic dist ??????????????????????????????N(0,1)?????????,???????????????????????????pdf logistic??????????????????N(0,1)???
# ????????????????????????,?????????0?????????logistics????????? (this is pdf)
# cdf ???N(0,1)???????????????,?????????0,???????????????????????????0,??????????????????
# N(0,1) pdf is pdf(dnorm), cdf(pnorm)
# points(x,...)... or plot(x,...)



# (d)
# ??????,g(pi)=log(pi/1-pi)?????????pi??????pi(x)????????????,?????????
# 1 ??????pi????????????,????????????????????????logistic regresssion???????????????
# 2 beta0???beta1??????????????????


##################

# Question 1 (c)

# PDF for the logistic distribution is:
PDF = function(y,mu,sigma){
  molecular = pi * exp(-(y-mu)*pi/(sigma*sqrt(3)))
  denominator = sigma*sqrt(3) * (1 + exp(-(y-mu)*pi/(sigma*sqrt(3))))^2
  return(molecular/denominator)
}

# CDF for the logistic distribution is:
CDF = function(y,mu,sigma){
  ans = 1 / (1 + exp(-(y-mu)*pi/(sigma*sqrt(3))))
  return(ans)
}

# For variance = 1, sigma is also equal to 1. PDF and CDF with mean 0 and variance 1 is as follows:

PDF(3,0,1)
# [1] 0.007792275

CDF(3,0,1)
# [1] 0.9956853

x = seq(-5,5,0.001)
y_pdf = sapply(x, function(s) PDF(s,0,1))
plot(x, y_pdf, xlab="range of data", ylab="range of y", main="logistic distribution PDF", type="l")
points(x, sapply(x, function(s) dnorm(s)), type="l", col="red")

y_cdf = sapply(x, function(s) CDF(s,0,1))
plot(x, y_cdf, xlab="range of data", ylab="range of y", main="logistic distribution CDF", type="l")
points(x, sapply(x, function(s) pnorm(s)), type="l", col="red")

# Question 1 (d)


##################

# Question 2

# (a)
# ??????:A???B?????????????????????????????????????????????????????????
m <- c(400,200,...) # No. cells samples
y <- c(3,5,...) # No. cell aberrant. a then b. y???????????????
# m-y????????????
resp <- cbind(y,m-y)
substance <- c("A","A",...) # ??????,substance
# factor(substance) # ??????:???substance??????????????????categorical variable

# ???????????????: dose <- c(0,20,...)

# ????????????
model1 <- glm(resp~factor(substance), family=binomial(link=logit))
summary(model1)

# ?????????:H0: beta_substance = 0 (beta_substance = log odds ratio of..?????????????????????A vs B)
# ??????beta_substance=0, then odds ratio of ... A vs B = 1
# => odds of A / odds of B = 1
# => odds of A = odds of B
# => A???B?????????
# ?????????summary,??????p-val??????0.05,reject H0,??????A???B?????????

################

# Question 2 (a)
sample = c(400,200,200,200,400,200,200,200,200)
aberrant = c(3,5,14,4,5,2,2,4,7)
substance = c("A","A","A","A","B","B","B","B","B")
dose = c(0.0001,20,100,200,0.0001,62.5,125.0,250.0,500.0)
resp = cbind(aberrant, sample-aberrant)
model1 = glm(resp ~ factor(substance), family=binomial(link=logit))
summary(model1)



################

# (b)
dose <- c(0,20,...) # dose
log_dose <- log(dose) # ????????????:?????????0,?????????take log...log(0)=-??????
# ????????????:??????dose???????????????1???????????????,?????????????????????

model2 <- glm(resp~dose + factor(substance), family=binomial(link=logit))
summary(model2)

model3 <- glm(resp ~ log(dose) + factor(substance), family=binomial(link=logit))

summary(model2)
summary(model3)
# ??????????????????,??????wald-based hypothesis test about beta_dose (every ml increase 1 mg) 
#   and beta_log_dose (logdose ????????????1?????????)???????????????????????????
# ???????????????1????????????????????????????????????,????????????????????????????????????????????????
# ????????????????????????,????????????


# (c)
# dose regression parameter = beta_dose => ??????model2
# 95 CI for beta_dose = beta_dose_hat +/- 1.96*se(beta_dose_hat)
# ??????regression parameter = ??????beta_dose_hat,????????????,??????course note or slides 2b or 2d??????
# log odds ratio... ???????????????1????????????????????????



# (d)
# best fitted logistic regression model <= ?????????2b?????????????????????
# to determine dose x
# ??????,??????pi=0.02,???beta??????????????????summary??????
# ???????????????A???B????????????,?????????????????????????????????????????????



# Question 3
COVIDdata =read.csv("journal.pone.0245327.s010.csv")
COVIDdata_NCSU = COVIDdata[(!is.na(COVIDdata$Source)&(COVIDdata$Source=="NCState")),names(COVIDdata)%in%
                             c("Health_General", "Hrs_Screen", "Hrs_Outdoor", "Hrs_Exercise", "Class_Self", "Infected_Any",
                               "Female", "BMI", "Educ_College_Grad", "Age", "Classification_High", "Ethnoracial_Group_White1_Asian2","Age_18to25")]
COVIDdata_NCSU = COVIDdata_NCSU[!is.na(COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2), ]
COVIDdata_NCSU$Infected_Any = factor(COVIDdata_NCSU$Infected_Any)
COVIDdata_NCSU$Educ_College_Grad = factor(COVIDdata_NCSU$Educ_College_Grad)
COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2 = factor(COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2)
COVIDdata_NCSU$Age_18to25 = factor(COVIDdata_NCSU$Age_18to25)

# (a)
# run model1
# provide estimate: ??????????????????????????????beta????????????beta_hat (log odds ratio)

# ??????beta take exponential?????????,??????log odds ratio ???take exponential => odds ratio
# ex, ?????????????????????????????????,hours screen?????????????????????,??????odds ratio???????????????
# infect any??????1???0,1????????????????????????0??????????????????????????????
# ??????????????????,?????????1,??????????????????????????????????????????????????????odds ratio????????????0,??????????????????????????????

COVIDdata =read.csv("journal.pone.0245327.s010.csv")
COVIDdata_NCSU = COVIDdata[(!is.na(COVIDdata$Source)&(COVIDdata$Source=="NCState")),names(COVIDdata)%in%
                             c("Health_General", "Hrs_Screen", "Hrs_Outdoor", "Hrs_Exercise", "Class_Self", 
                               "Infected_Any","Female", "BMI", "Educ_College_Grad", "Age", "Classification_High",
                               "Ethnoracial_Group_White1_Asian2","Age_18to25")]
COVIDdata_NCSU = COVIDdata_NCSU[!is.na(COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2), ]
COVIDdata_NCSU$Infected_Any = factor(COVIDdata_NCSU$Infected_Any)
COVIDdata_NCSU$Educ_College_Grad = factor(COVIDdata_NCSU$Educ_College_Grad)
COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2 = factor(COVIDdata_NCSU$Ethnoracial_Group_White1_Asian2)
COVIDdata_NCSU$Age_18to25 = factor(COVIDdata_NCSU$Age_18to25)

model1 = glm(Classification_High~Female+Age+Ethnoracial_Group_White1_Asian2+Class_Self+
               Health_General+BMI+Hrs_Screen+Hrs_Outdoor+Hrs_Exercise+Educ_College_Grad+Infected_Any,
             family=binomial(link=logit), data=COVIDdata_NCSU)
summary(model1)

# (b)
# model2??????model1?????????age??????,??????deviance test??????age?????????
# ??????H0??????beta????????????model2???reduced model,model1 is full model
# full model: log(pi/1-pi) = ... (where pi is ????????????????????????????????????????????????)
# ??????
# H0:... ??? D = ... ~ chisq(...)
# p-val = ... see course notes full vs reduced
# deviance test case 2
# ??????????????????full model = model1 (xi1,xi2,xi3,xi4,xi5), 
# reduced model = model2 (xi1,xi6,...)

model2 = glm(Classification_High~Female+Ethnoracial_Group_White1_Asian2+Class_Self+
               Health_General+BMI+Hrs_Screen+Hrs_Outdoor+Hrs_Exercise+Educ_College_Grad+Infected_Any,
             family=binomial(link=logit), data=COVIDdata_NCSU)
summary(model2)


# (c)
# ???age18-25??????age,??????model3 (reduced),model1 is still full model
# ??????

model3 = glm(Classification_High~Female+Age_18to25+Ethnoracial_Group_White1_Asian2+Class_Self+
               Health_General+BMI+Hrs_Screen+Hrs_Outdoor+Hrs_Exercise+Educ_College_Grad+Infected_Any,
             family=binomial(link=logit), data=COVIDdata_NCSU)
summary(model3)

# (d)
# model3
# ???????????????????????????/????????????
# x <- c(1,1,....)   (beta0,beta1,...)
# ??????


# ????????????names(tmp)
v = tmp$cov.unscaled
x = c(1,1,..) #???????????????
x = as.matrix(x,..,1) # ????????????????????????,????????????????????????
t(x) %*% v %*% x # ??????????????????Var(xx-xx)??????std error,????????????slides
########################
tmp = summary.glm(model3)
v = tmp$cov.unscaled

# x vector
x = c(1,1,1,2,2,1,4,15,8,1,1,0,1)
x = as.matrix(x,13,1)
dim(x)

# compute variance estimate
t(x)%*%v%*%x

beta_hat = c(0.16177767,0.64180195,-0.32862891,0.26910351,0.53315063,-0.16061353,-0.22425709,0.00567121,0.03367899,-0.04988226,0.03354474,0.01268919,0.37185963)
beta_hat = as.matrix(beta_hat,13,1)


########################

# (e)
# ??????,???probability?????????pi



# (f)
# summary??????????????????highlight???????????????????????????
# ????????????H0?????????????????????????????????????????????,??????p-val??????0or??????0
# ??????????????????:????????????positive,??????negative??????(??????log odds ratio)
# ????????????????????????beta?????????take exponential, if odds ratio >1,odds?????????????????????1,0-1,???odds??????










